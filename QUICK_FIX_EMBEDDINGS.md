# ğŸš€ Quick Fix: Embedding Errors in Production

## The Problem You're Seeing

```
[ERROR] OpenAI embedding generation failed
[ERROR] Failed to load local embedding model
Error: libonnxruntime.so.1.14.0: cannot open shared object file: No such file or directory
```

**Why this happens:** When you visit the admin embeddings page, it automatically tests both providers. If OpenAI isn't configured and local embeddings can't load native libraries, you see these errors.

## âš¡ Quick Solution (2 minutes)

### Step 1: Choose Your Approach

#### Option A: Use OpenAI (RECOMMENDED - Fastest & Easiest)

**In Dokploy Environment Variables, add:**

```
EMBEDDING_PROVIDER=openai
OPENAI_API_KEY=sk-your-actual-openai-api-key
```

Then click **Redeploy**. Done! âœ…

**Cost:** ~$0.13 per 1 million tokens (very cheap)

---

#### Option B: Fix Local Embeddings (If you don't want to use OpenAI)

**Step 1:** Commit and push these changes:

```bash
git add .
git commit -m "Fix: Add ONNX Runtime for local embeddings"
git push
```

**Step 2:** In Dokploy, click **Rebuild** (not just redeploy)

**Step 3:** Wait for build to complete. Done! âœ…

---

## ğŸ” What Changed?

We made four key improvements:

1. **Added ONNX Runtime to nixpacks.toml**
   - Now includes the native library that was missing (`onnxruntime` package)

2. **Improved WASM fallback in local-provider.ts**
   - Better configuration for WASM-only mode
   - More explicit backend selection
   - Forces WASM execution providers

3. **Better error logging**
   - Dependency errors now log at DEBUG level (not ERROR)
   - Configuration errors are handled gracefully
   - No more log spam when providers aren't configured

4. **Graceful admin panel testing**
   - Admin endpoints now handle provider test failures silently
   - Shows clear status without spamming error logs

## âœ… Verify It's Working

After redeploying, check your logs:

**If using OpenAI:**
```
[INFO] Using OpenAI embedding provider
[INFO] Generated embedding for article: xxx
```

**If using local embeddings (native):**
```
[INFO] Local embedding model loaded successfully {"backend":"native"}
```

**If using local embeddings (WASM):**
```
[INFO] Local embedding model loaded successfully {"backend":"wasm"}
```

**What you WON'T see anymore:**
- âŒ `[ERROR] OpenAI embedding generation failed` (when not configured)
- âŒ `[ERROR] Failed to load local embedding model` (when dependencies missing)
- âŒ Repeated error logs every minute

**What you WILL see instead:**
- âœ… `[DEBUG]` level logs for expected failures (only visible if debug logging is enabled)
- âœ… Clean logs showing only the active provider
- âœ… Admin panel shows provider status without errors

## ğŸ’¡ Recommendation

**Use OpenAI in production** because:
- âš¡ Much faster (100x+)
- ğŸ¯ Better quality
- ğŸ’° Very cheap (~$0.13 per 1M tokens)
- ğŸ”§ No infrastructure complexity
- ğŸ“ˆ Scales effortlessly

**Use local embeddings only if:**
- ğŸ”’ You need complete data privacy
- ğŸ’¸ You want zero API costs
- ğŸŒ You're okay with slower performance

## ğŸ“Š Quick Comparison

| Metric | OpenAI | Local (Fixed) |
|--------|--------|---------------|
| Speed | âš¡âš¡âš¡ | âš¡ |
| Quality | â­â­â­ | â­â­ |
| Cost | $0.13/1M tokens | Free |
| Memory | ~50MB | ~500MB-1GB |
| Setup | 1 env var | Rebuild needed |

## ğŸ†˜ Still Having Issues?

1. **Double-check environment variables** in Dokploy
2. **Do a clean rebuild** (not just redeploy)
3. **Check the logs** for "Initializing local embedding model"
4. **See full documentation:** `docs/PRODUCTION_EMBEDDING_FIX.md`

## ğŸ“ Files Changed

- âœ… `nixpacks.toml` - Added ONNX Runtime package + environment variables
- âœ… `src/lib/embeddings/local-provider.ts` - Improved WASM configuration + debug logging
- âœ… `src/lib/embeddings/openai-provider.ts` - Better error handling + debug logging
- âœ… `app/api/admin/embeddings/config/route.ts` - Graceful provider testing
- âœ… `app/api/admin/embeddings/provider/route.ts` - Graceful provider testing
- âœ… `docs/PRODUCTION_EMBEDDING_FIX.md` - Full documentation

## ğŸ¯ Summary

**The core issue:** Admin panel was testing both embedding providers on every page load, causing error log spam when providers weren't configured or dependencies were missing.

**The fix:**
1. **Immediate relief:** Changed error logging to debug level for expected failures
2. **Long-term fix:** Added ONNX Runtime to nixpacks for native support
3. **Better UX:** Admin panel now handles provider failures gracefully

**Result:** Clean logs, no more error spam, and both solutions (OpenAI or local) work properly.

